{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f40befdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "response = requests.get(\"https://www.cars24.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6bdb1311",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.cars24.com/buy-used-cars-bangalore/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1231cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: Message: \n",
      "Stacktrace:\n",
      "Symbols not available. Dumping unresolved backtrace:\n",
      "\t0x634103\n",
      "\t0x634144\n",
      "\t0x43e71d\n",
      "\t0x48a03d\n",
      "\t0x48a41b\n",
      "\t0x4d17f2\n",
      "\t0x4ac954\n",
      "\t0x4cee17\n",
      "\t0x4ac706\n",
      "\t0x47da30\n",
      "\t0x47ed54\n",
      "\t0x8a57b4\n",
      "\t0x8a098a\n",
      "\t0x65c392\n",
      "\t0x64c4c8\n",
      "\t0x65324d\n",
      "\t0x63c478\n",
      "\t0x63c63c\n",
      "\t0x6267ca\n",
      "\t0x75fd5d49\n",
      "\t0x771dd6db\n",
      "\t0x771dd661\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "\n",
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "driver.get(url)  # Replace with the actual URL\n",
    "\n",
    "try:\n",
    "    # Step 1: Explicit wait for a key element to ensure initial content is loaded\n",
    "    # Replace '.data-class' with the actual CSS selector of an element that indicates data is loaded\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, '.data-class'))\n",
    "    )\n",
    "\n",
    "    # Step 2: Handle infinite scroll to load all content\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)  # Brief pause to allow new content to load\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:  # No more content to load\n",
    "            break\n",
    "        last_height = new_height\n",
    "        \n",
    "    html = driver.page_source\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    html = driver.page_source  # Capture whatever is available on error\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n",
    "\n",
    "# Optional: Save the HTML to a file for inspectio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e581079",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"cars.html\", \"w\") as f:\n",
    "    f.write(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "736e28a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found scroll container with selector: div[class*='container']\n",
      "Starting scroll process...\n",
      "Scroll 1: Height 179 -> 179\n",
      "Scroll 2: Height 179 -> 179\n",
      "No change in height (count: 1)\n",
      "Scroll 3: Height 179 -> 179\n",
      "No change in height (count: 2)\n",
      "Scroll 4: Height 179 -> 179\n",
      "No change in height (count: 3)\n",
      "Reached bottom of page\n",
      "Successfully scraped page. HTML length: 3333106 characters\n",
      "HTML saved to scraped_page.html\n",
      "Driver closed\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "import time\n",
    "\n",
    "# Configure Chrome options for better performance\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "chrome_options.add_argument('--start-maximized')\n",
    "chrome_options.add_argument('--disable-gpu')\n",
    "chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "chrome_options.add_experimental_option('useAutomationExtension', False)\n",
    "\n",
    "# Initialize driver\n",
    "driver = webdriver.Chrome(\n",
    "    service=Service(ChromeDriverManager().install()),\n",
    "    options=chrome_options\n",
    ")\n",
    "\n",
    "# Set page load timeout\n",
    "driver.set_page_load_timeout(30)\n",
    "\n",
    "try:\n",
    "    # Replace 'banglore' with your actual URL\n",
    "    url = url  # Make sure this is a valid URL string\n",
    "    driver.get(url)\n",
    "    \n",
    "    # Wait for page to load completely\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Wait for main scroll container with multiple possible selectors\n",
    "    scroll_container = None\n",
    "    selectors = [\n",
    "        \"div.qk-container\",\n",
    "        \"div[class*='scroll']\",\n",
    "        \"div[class*='container']\",\n",
    "        \"body\"  # Fallback to body if specific container not found\n",
    "    ]\n",
    "    \n",
    "    for selector in selectors:\n",
    "        try:\n",
    "            scroll_container = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, selector))\n",
    "            )\n",
    "            print(f\"Found scroll container with selector: {selector}\")\n",
    "            break\n",
    "        except TimeoutException:\n",
    "            continue\n",
    "    \n",
    "    if not scroll_container:\n",
    "        print(\"No scroll container found, using page body\")\n",
    "        scroll_container = driver.find_element(By.TAG_NAME, \"body\")\n",
    "    \n",
    "    # Enhanced scrolling with multiple strategies\n",
    "    print(\"Starting scroll process...\")\n",
    "    last_height = 0\n",
    "    scroll_attempts = 0\n",
    "    max_scroll_attempts = 50  # Prevent infinite loops\n",
    "    no_change_count = 0\n",
    "    max_no_change = 3  # Stop after 3 consecutive no-change scrolls\n",
    "    \n",
    "    while scroll_attempts < max_scroll_attempts:\n",
    "        # Get current height before scroll\n",
    "        current_height = driver.execute_script(\n",
    "            \"return arguments[0].scrollHeight;\", \n",
    "            scroll_container\n",
    "        )\n",
    "        \n",
    "        # Scroll down\n",
    "        driver.execute_script(\n",
    "            \"arguments[0].scrollTo(0, arguments[0].scrollHeight);\",\n",
    "            scroll_container\n",
    "        )\n",
    "        \n",
    "        # Wait for content to load\n",
    "        time.sleep(3)  # Increased wait time\n",
    "        \n",
    "        # Try clicking \"Load More\" or \"Show More\" buttons if they exist\n",
    "        try:\n",
    "            load_more_buttons = driver.find_elements(\n",
    "                By.XPATH, \n",
    "                \"//*[contains(text(), 'Load More') or contains(text(), 'Show More') or contains(text(), 'View More')]\"\n",
    "            )\n",
    "            for button in load_more_buttons:\n",
    "                if button.is_displayed():\n",
    "                    driver.execute_script(\"arguments[0].click();\", button)\n",
    "                    print(\"Clicked 'Load More' button\")\n",
    "                    time.sleep(2)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "        \n",
    "        # Get new height after scroll\n",
    "        new_height = driver.execute_script(\n",
    "            \"return arguments[0].scrollHeight;\", \n",
    "            scroll_container\n",
    "        )\n",
    "        \n",
    "        print(f\"Scroll {scroll_attempts + 1}: Height {current_height} -> {new_height}\")\n",
    "        \n",
    "        # Check if height changed\n",
    "        if new_height == last_height:\n",
    "            no_change_count += 1\n",
    "            print(f\"No change in height (count: {no_change_count})\")\n",
    "            \n",
    "            # Try scrolling up slightly and back down to trigger lazy loading\n",
    "            driver.execute_script(\n",
    "                \"arguments[0].scrollTo(0, arguments[0].scrollHeight - 500);\",\n",
    "                scroll_container\n",
    "            )\n",
    "            time.sleep(1)\n",
    "            driver.execute_script(\n",
    "                \"arguments[0].scrollTo(0, arguments[0].scrollHeight);\",\n",
    "                scroll_container\n",
    "            )\n",
    "            time.sleep(2)\n",
    "            \n",
    "            if no_change_count >= max_no_change:\n",
    "                print(\"Reached bottom of page\")\n",
    "                break\n",
    "        else:\n",
    "            no_change_count = 0  # Reset counter if height changed\n",
    "        \n",
    "        last_height = new_height\n",
    "        scroll_attempts += 1\n",
    "    \n",
    "    # Final wait to ensure all content is loaded\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Get the page source\n",
    "    html = driver.page_source\n",
    "    \n",
    "    print(f\"Successfully scraped page. HTML length: {len(html)} characters\")\n",
    "    \n",
    "    # Optional: Save HTML to file for inspection\n",
    "    with open(\"scraped_page.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html)\n",
    "    print(\"HTML saved to scraped_page.html\")\n",
    "    \n",
    "    # You can now parse the HTML with BeautifulSoup or extract specific elements\n",
    "    # Example:\n",
    "    # from bs4 import BeautifulSoup\n",
    "    # soup = BeautifulSoup(html, 'html.parser')\n",
    "    # data = soup.find_all('div', class_='your-data-class')\n",
    "    \n",
    "except TimeoutException as e:\n",
    "    print(f\"Timeout error: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "finally:\n",
    "    driver.quit()\n",
    "    print(\"Driver closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e3de92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading URL: https://www.cars24.com/buy-used-cars-bangalore/\n",
      "Waiting for network to settle...\n",
      "Document ready state: complete\n",
      "‚úì Found 1 elements with selector: div[class*='item']\n",
      "\n",
      "Starting intelligent scroll...\n",
      "Scroll 1: Found 1552 total elements\n",
      "Scroll 2: Found 1552 total elements\n",
      "No new elements loaded, stopping scroll\n",
      "\n",
      "‚úì Captured HTML: 1635784 characters\n",
      "‚úì HTML saved to scraped_page_full.html\n",
      "‚úì Screenshot saved to page_final.png\n",
      "\n",
      "--- Content Analysis ---\n",
      "Total HTML length: 1,635,784 characters\n",
      "Contains <div> tags: 1465\n",
      "Contains <article> tags: 0\n",
      "Contains <li> tags: 155\n",
      "Contains <script> tags: 93\n",
      "Extracted text length: 31,617 characters\n",
      "\n",
      "First 500 characters of content:\n",
      "Used Cars in Bangalore - 2148 Second Hand Cars | CARS24 Bangalore Buy used car Buy Used Cars in Bangalore Change city Browse by Model Browse by Make Browse by Price Browse by Body Type Browse by Fuel Type Browse by Transmission Browse by City Browse by Model Used Hyundai i10 Cars in Bangalore Used Hyundai i20 Cars in Bangalore Used Renault Kwid Cars in Bangalore Used Tata NEXON Cars in Bangalore Used Maruti Swift Cars in Bangalore Used Maruti Alto Cars in Bangalore Used Maruti Baleno Cars in Ban\n",
      "\n",
      "‚úì Text content saved to scraped_text.txt\n",
      "\n",
      "--- Network Analysis ---\n",
      "Found 26 potential API calls:\n",
      "\n",
      "‚ùå Error: 'set' object is not subscriptable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_6600\\1953122559.py\", line 168, in <module>\n",
      "    for api_url in set(api_calls)[:10]:  # Show first 10 unique\n",
      "                   ~~~~~~~~~~~~~~^^^^^\n",
      "TypeError: 'set' object is not subscriptable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Driver closed\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import time\n",
    "import json\n",
    "\n",
    "# Configure Chrome options with performance logging\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "chrome_options.add_argument('--start-maximized')\n",
    "chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "chrome_options.add_experimental_option('useAutomationExtension', False)\n",
    "\n",
    "# Enable performance logging to capture network requests\n",
    "chrome_options.set_capability('goog:loggingPrefs', {'performance': 'ALL'})\n",
    "\n",
    "# Initialize driver\n",
    "driver = webdriver.Chrome(\n",
    "    service=Service(ChromeDriverManager().install()),\n",
    "    options=chrome_options\n",
    ")\n",
    "\n",
    "try:\n",
    "    # Replace with your actual URL\n",
    "    url = url\n",
    "    print(f\"Loading URL: {url}\")\n",
    "    driver.get(url)\n",
    "    \n",
    "    # Wait for network idle (no new requests for 2 seconds)\n",
    "    print(\"Waiting for network to settle...\")\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Wait for document ready state\n",
    "    WebDriverWait(driver, 30).until(\n",
    "        lambda d: d.execute_script('return document.readyState') == 'complete'\n",
    "    )\n",
    "    print(\"Document ready state: complete\")\n",
    "    \n",
    "    # Wait for specific elements that indicate data is loaded\n",
    "    # Adjust these selectors based on your target website\n",
    "    possible_selectors = [\n",
    "        \"div[class*='product']\",\n",
    "        \"div[class*='item']\",\n",
    "        \"div[class*='card']\",\n",
    "        \"li[class*='list']\",\n",
    "        \"article\",\n",
    "        \"div[data-testid]\",\n",
    "        \"div[id*='item']\"\n",
    "    ]\n",
    "    \n",
    "    element_found = False\n",
    "    for selector in possible_selectors:\n",
    "        try:\n",
    "            elements = WebDriverWait(driver, 5).until(\n",
    "                EC.presence_of_all_elements_located((By.CSS_SELECTOR, selector))\n",
    "            )\n",
    "            if elements:\n",
    "                print(f\"‚úì Found {len(elements)} elements with selector: {selector}\")\n",
    "                element_found = True\n",
    "                break\n",
    "        except TimeoutException:\n",
    "            continue\n",
    "    \n",
    "    if not element_found:\n",
    "        print(\"‚ö† No standard content elements found, trying alternate approach...\")\n",
    "    \n",
    "    # Scroll to load all content\n",
    "    print(\"\\nStarting intelligent scroll...\")\n",
    "    last_count = 0\n",
    "    scroll_pause = 3\n",
    "    max_scrolls = 30\n",
    "    \n",
    "    for i in range(max_scrolls):\n",
    "        # Scroll down\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(scroll_pause)\n",
    "        \n",
    "        # Count visible elements\n",
    "        try:\n",
    "            current_count = len(driver.find_elements(By.CSS_SELECTOR, \"div, article, li\"))\n",
    "            print(f\"Scroll {i+1}: Found {current_count} total elements\")\n",
    "            \n",
    "            if current_count == last_count:\n",
    "                print(\"No new elements loaded, stopping scroll\")\n",
    "                break\n",
    "            last_count = current_count\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Try to click any \"Load More\" buttons\n",
    "        try:\n",
    "            load_more = driver.find_elements(By.XPATH, \n",
    "                \"//*[contains(translate(text(), 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', 'abcdefghijklmnopqrstuvwxyz'), 'load more') or \" +\n",
    "                \"contains(translate(text(), 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', 'abcdefghijklmnopqrstuvwxyz'), 'show more')]\"\n",
    "            )\n",
    "            for btn in load_more:\n",
    "                if btn.is_displayed():\n",
    "                    driver.execute_script(\"arguments[0].click();\", btn)\n",
    "                    print(\"Clicked 'Load More' button\")\n",
    "                    time.sleep(3)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Final wait\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Get the rendered HTML\n",
    "    html = driver.page_source\n",
    "    print(f\"\\n‚úì Captured HTML: {len(html)} characters\")\n",
    "    \n",
    "    # Save HTML\n",
    "    with open(\"scraped_page_full.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html)\n",
    "    print(\"‚úì HTML saved to scraped_page_full.html\")\n",
    "    \n",
    "    # Take screenshot\n",
    "    driver.save_screenshot(\"page_final.png\")\n",
    "    print(\"‚úì Screenshot saved to page_final.png\")\n",
    "    \n",
    "    # Analyze content\n",
    "    print(\"\\n--- Content Analysis ---\")\n",
    "    print(f\"Total HTML length: {len(html):,} characters\")\n",
    "    print(f\"Contains <div> tags: {html.count('<div')}\")\n",
    "    print(f\"Contains <article> tags: {html.count('<article')}\")\n",
    "    print(f\"Contains <li> tags: {html.count('<li')}\")\n",
    "    print(f\"Contains <script> tags: {html.count('<script')}\")\n",
    "    \n",
    "    # Try to extract data using common patterns\n",
    "    from bs4 import BeautifulSoup\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # Remove script and style tags for cleaner content\n",
    "    for script in soup([\"script\", \"style\"]):\n",
    "        script.decompose()\n",
    "    \n",
    "    # Get text content\n",
    "    text = soup.get_text(separator=' ', strip=True)\n",
    "    print(f\"Extracted text length: {len(text):,} characters\")\n",
    "    print(f\"\\nFirst 500 characters of content:\\n{text[:500]}\")\n",
    "    \n",
    "    # Save text content\n",
    "    with open(\"scraped_text.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(text)\n",
    "    print(\"\\n‚úì Text content saved to scraped_text.txt\")\n",
    "    \n",
    "    # Optional: Capture network requests (API calls that might contain data)\n",
    "    print(\"\\n--- Network Analysis ---\")\n",
    "    logs = driver.get_log('performance')\n",
    "    api_calls = []\n",
    "    \n",
    "    for log in logs:\n",
    "        try:\n",
    "            message = json.loads(log['message'])['message']\n",
    "            if message['method'] == 'Network.responseReceived':\n",
    "                url = message['params']['response']['url']\n",
    "                if 'api' in url.lower() or 'json' in url.lower():\n",
    "                    api_calls.append(url)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    if api_calls:\n",
    "        print(f\"Found {len(api_calls)} potential API calls:\")\n",
    "        for api_url in set(api_calls)[:10]:  # Show first 10 unique\n",
    "            print(f\"  - {api_url}\")\n",
    "        print(\"\\nüí° Tip: You might be able to scrape data directly from these API endpoints!\")\n",
    "    else:\n",
    "        print(\"No obvious API calls found\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "finally:\n",
    "    driver.quit()\n",
    "    print(\"\\n‚úì Driver closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a70d0d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
